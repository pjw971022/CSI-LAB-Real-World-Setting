env_name: rlbench
task_name: pour_from_cup_to_cup
context_mode: user_command
planner:
  stop_threshold: 0.001
  savgol_polyorder: 3
  savgol_window_size: 20
  obstacle_map_weight: 1
  max_steps: 300
  obstacle_map_gaussian_sigma: 10
  target_map_weight: 2
  stop_criteria: no_nearby_equal
  target_spacing: 1
  max_curvature: 3
  pushing_skip_per_k: 5
controller:
  horizon_length: 1
  num_samples: 10000
  ee_local: temperature
  ee_local_radius: 0.15
visualizer:
  save_dir: ./visualizations
  quality: low
  map_size: 100
lmp_config:
  env:
    map_size: 100
    num_waypoints_per_plan: 10000
    max_plan_iter: 1
    visualize: true
  lmps:
    planner:
      prompt_fname: planner_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - 'objects = '
      maintain_session: false
      include_context: true
      has_return: false
      return_val_name: ret_val
      load_cache: true
    composer:
      prompt_fname: composer_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - objects =
      maintain_session: false
      include_context: false
      has_return: false
      return_val_name: ret_val
      load_cache: true
    parse_query_obj:
      prompt_fname: parse_query_obj_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - objects =
      maintain_session: false
      include_context: true
      has_return: true
      return_val_name: ret_val
      load_cache: true
    get_affordance_map:
      prompt_fname: get_affordance_map_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - objects =
      maintain_session: false
      include_context: false
      has_return: true
      return_val_name: ret_val
      load_cache: true
    get_avoidance_map:
      prompt_fname: get_avoidance_map_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - objects =
      maintain_session: false
      include_context: false
      has_return: true
      return_val_name: ret_val
      load_cache: true
    get_velocity_map:
      prompt_fname: get_velocity_map_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - objects =
      maintain_session: false
      include_context: false
      has_return: true
      return_val_name: ret_val
      load_cache: true
    get_rotation_map:
      prompt_fname: get_rotation_map_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - objects =
      maintain_session: false
      include_context: false
      has_return: true
      return_val_name: ret_val
      load_cache: true
    get_gripper_map:
      prompt_fname: get_gripper_map_prompt
      model: gpt-4
      max_tokens: 512
      temperature: 0
      query_prefix: '# Query: '
      query_suffix: .
      stop:
      - '# Query: '
      - objects =
      maintain_session: false
      include_context: false
      has_return: true
      return_val_name: ret_val
      load_cache: true
